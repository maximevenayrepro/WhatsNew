# AI Task Planning Template - Starter Framework

---

## 1. Task Overview

### Task Title
**Title:** Am√©liorer le prompt syst√®me Perplexity pour obtenir des r√©sultats plus fiables et structur√©s

### Goal Statement
**Goal:** Optimiser le prompt syst√®me et utilisateur envoy√© √† l'API Perplexity pour maximiser la qualit√©, la fiabilit√© et la structure des r√©ponses (titres, snippets, URLs valides).

---

## 2. Project Analysis & Current State

### Technology & Architecture
- **Frameworks & Versions:** FastAPI, Perplexity API (sonar model)
- **Language:** Python 3.11+
- **Database & ORM:** None

### Current State
Le service `perplexity_client.py` envoie un prompt syst√®me et utilisateur basique. Les r√©sultats sont inconstants : parfois bien structur√©s (TITLE/SNIPPET/URL), parfois incomplets ou mal format√©s, n√©cessitant le fallback d'extraction d'URLs.

---

## 3. Context & Problem Definition

### Problem Statement
Le prompt actuel ne garantit pas une r√©ponse structur√©e fiable. L'API Perplexity peut retourner du texte non format√©, des URLs manquantes, ou des snippets trop longs/courts. Le taux de recours au fallback d'extraction d'URLs est √©lev√©.

### Success Criteria
- [ ] Prompt syst√®me et utilisateur optimis√©s avec instructions claires et exemples
- [ ] Taux de parsing structur√© (regex TITLE/SNIPPET/URL) > 80% sur tests r√©els
- [ ] R√©duction des appels au fallback d'extraction d'URLs
- [ ] Snippets concis (1-2 phrases) et URLs toujours pr√©sentes
- [ ] Validation et logs d√©taill√©s sur la qualit√© des r√©ponses

---

## 4. Development Mode Context
Local-only ; priorit√© √† la qualit√© des r√©sultats pour am√©liorer l'UX.

---

## 5. Technical Requirements

### Functional Requirements
- Am√©liorer le prompt syst√®me avec :
  - Instructions explicites sur le format de sortie
  - Exemples concrets de format attendu (few-shot)
  - Contraintes claires (URLs obligatoires, snippets brefs)
- Ajuster le prompt utilisateur pour sp√©cifier le d√©lai (24h ou 7 jours) et le nombre exact de r√©sultats
- Ajouter validation c√¥t√© parsing : log des r√©ponses mal structur√©es pour analyse

### Non-Functional Requirements
- **Fiabilit√©:** R√©duire la variabilit√© des formats de r√©ponse
- **Performance:** Maintenir le timeout actuel (30s)
- **Observabilit√©:** Logger les r√©ponses brutes pour debug et it√©ration

### Technical Constraints
- Pas de changement au mod√®le Perplexity (sonar)
- Conserver le parsing existant (regex + fallback) comme filet de s√©curit√©

---

## 6. Data & Database Changes
None.

---

## 7. API & Backend Changes
- Modifier `server/services/perplexity_client.py` :
  - Am√©liorer le prompt syst√®me (`system` role)
  - Am√©liorer le prompt utilisateur (`user` role)
  - Optionnel : ajouter des param√®tres API (temp√©rature, etc.) pour stabilit√©

---

## 8. Frontend Changes
None. Impact transparent pour l'utilisateur final (meilleure qualit√© des r√©sultats affich√©s).

---

## 9. Implementation Plan
1. **Recherche & benchmark:** Tester diff√©rentes variantes de prompts avec l'API Perplexity
2. **Prompt syst√®me:** Ajouter exemples few-shot, renforcer contraintes de format
3. **Prompt utilisateur:** Clarifier d√©lai et nombre de r√©sultats
4. **Validation:** Tester sur plusieurs topics (technologie, politique, sport, etc.)
5. **Logging:** Logger r√©ponses brutes pour analyse post-d√©ploiement
6. **It√©ration:** Ajuster en fonction des logs et taux de parsing

---

## 10. Task Completion Tracking
- Tests manuels sur 5+ topics diff√©rents
- V√©rifier logs : taux de matches regex vs fallback
- Comparer avant/apr√®s : qualit√© des snippets et pr√©sence d'URLs

### Documentation Updates
- Update `README.md` only for user-facing changes (features, installation, run instructions)
- Update `ARCHITECTURE.md` for technical changes (data models, services, API endpoints, architecture)

---

## 11. File Structure & Organization
- `server/services/perplexity_client.py` (m√©thode `search_latest` et `_parse_response`)

---

## 12. AI Agent Instructions
1) Analyser le prompt actuel et identifier faiblesses (manque d'exemples, instructions vagues)
2) Proposer 2-3 variantes de prompts am√©lior√©s (avec few-shot examples)
3) Impl√©menter la meilleure variante
4) Tester sur plusieurs topics et logger les r√©sultats
5) Ajuster si n√©cessaire en fonction des logs

### Testing Procedure
**üö® CRITICAL:** Before testing any changes, always follow the complete testing sequence defined in `.cursor/local-testing-procedure.mdc`:

1. **Clean port 8000**: Kill any existing process
2. **Setup venv**: Create/activate virtual environment and install dependencies
3. **Launch server**: `venv\Scripts\Activate.ps1; uvicorn server.main:app --reload`
4. **Verify health**: Test `http://127.0.0.1:8000/api/health` returns `{"status":"ok"}`
5. **Test topics:** Call `/api/get_news` with various topics and verify response quality

‚ö†Ô∏è **Never skip venv activation before running uvicorn** - it will fail with "command not found"

### Communication Preferences
Proposer plusieurs variantes de prompt avant impl√©mentation ; expliquer rationale des choix.

### Code Quality Standards
Maintenir types explicites ; commenter les changements significatifs au prompt ; logger r√©ponses brutes pour debug.

---

## 13. Second-Order Impact Analysis

### Impact Assessment
**Risques:**
- Un prompt trop contraignant pourrait r√©duire la richesse des r√©ponses
- Co√ªt API inchang√© mais meilleur ROI par requ√™te
- N√©cessite validation continue (LLMs peuvent changer de comportement)

**B√©n√©fices:**
- UX am√©lior√©e : r√©sultats plus fiables et pr√©sentables
- Moins de cas edge √† g√©rer c√¥t√© parsing
- Base pour futures am√©liorations (filtres, classement, etc.)


